title Sitewide Search Pipeline - Part 2 Publish Search Pipeline

autonumber
entryspacing 1.0

database Kafka content updated

note over Kafka content updated: Florence user published a collection\nvia Zebedee triggering an update\nto existing search index for sitewide search

note over Kafka content updated: OR

note over Kafka content updated: Messages produced by a reindex job, see\n"Part 1 - Trigger Reindex Pipeline"

Kafka content updated-->Search Data Extractor: TCP: Consume Kafka message

Search Data Extractor->Zebedee: Https Get: Zebedee resource

database Zebedee Content
Zebedee->Zebedee Content: I/O: READ JSON file from disc

Search Data Extractor->Dataset API: Http: GET Dataset resource

database Mongo DB
Dataset API->Mongo DB: TCP/IO socket: Find dataset

database Kafka search data import
Search Data Extractor-->Kafka search data import: TCP: Produce Kafka message

Kafka search data import-->Search Data Importer: TCP: Consume Kafka message

Search Data Importer->ElasticSearch: Http: GET Multi-operational request\n              to update/add docs

note over Search Data Importer: If the batch request to Elasticsearch\nis for a reindex job, process continues\notherwise process finishes here.

database Kafka search data imported
Search Data Importer-->Kafka search data imported: TCP: Produce Kafka message

note over Kafka search data imported: The search data imported topic is consumed\nby the Search Import Tracker, see\n"Part 3 - Trigger Search Reindex Tracker"\nfor continuation of the reindex pipeline